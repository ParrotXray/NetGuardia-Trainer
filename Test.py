"""
æ¸¬è©¦éšæ®µï¼ˆæœ€çµ‚æ”¹è‰¯ç‰ˆï¼‰ï¼š
- è‡ªå‹•è¼‰å…¥æœ€ä½³é–€æª»
- å¤šé–€æª»ç­–ç•¥æ¸¬è©¦
- è©³ç´°çš„æ”»æ“Šé¡å‹åˆ†æ
- æ¼å ±/èª¤å ±æ·±åº¦åˆ†æ
"""
import pandas as pd
import numpy as np
import joblib
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

print("=" * 50)
print("ğŸ§ª Step 4: æ¨¡å‹æ¸¬è©¦ï¼ˆæœ€çµ‚æ”¹è‰¯ç‰ˆï¼‰")
print("=" * 50)

# === 1ï¸âƒ£ è¼‰å…¥æ¨¡å‹èˆ‡å·¥å…· ===
print("ğŸ“¦ è¼‰å…¥æ¨¡å‹èˆ‡å·¥å…·...")
autoencoder = load_model("autoencoder_cic_model.h5", compile=False)
mlp = load_model("mlp_attack_classifier.h5")
scaler = joblib.load("scaler_ae.pkl")
le = joblib.load("label_encoder.pkl")

# è¼‰å…¥é–€æª»è³‡è¨Š
try:
    threshold_info = joblib.load("threshold_info.pkl")
    recommended_threshold = threshold_info['threshold']
    threshold_strategy = threshold_info['strategy']
    all_thresholds = threshold_info.get('all_thresholds', {})
    best_results = threshold_info.get('best_results', {})

    print(f"âœ… è¼‰å…¥æ¨è–¦é–€æª»: {recommended_threshold:.6f}")
    print(f"ğŸ“Š é–€æª»ç­–ç•¥: {threshold_strategy}")
    print(f"ğŸ“ˆ è¨“ç·´æ™‚ F1-Score: {best_results.get('f1', 0):.4f}")
except:
    recommended_threshold = None
    threshold_strategy = "Not found"
    all_thresholds = {}
    print("âš ï¸ æœªæ‰¾åˆ°æ¨è–¦é–€æª»")

print("âœ… æ¨¡å‹èˆ‡å·¥å…·å·²è¼‰å…¥æˆåŠŸ")

# === 2ï¸âƒ£ è®€å–æ¸¬è©¦è³‡æ–™ ===
test_file = "Wednesday-workingHours.pcap_ISCX.csv"
df = pd.read_csv(test_file)
df.columns = df.columns.str.strip()

print(f"\nâœ… è¼‰å…¥æ¸¬è©¦è³‡æ–™: {df.shape}")
print(f"ğŸ“‹ æ¸¬è©¦è³‡æ–™æ¨™ç±¤åˆ†å¸ƒ:\n{df['Label'].value_counts()}")

labels = df['Label'].copy()

# === 3ï¸âƒ£ æº–å‚™ç‰¹å¾µ ===
drop_cols = ['Flow ID', 'Source IP', 'Destination IP', 'Timestamp', 'Label']
df_features = df.drop(columns=drop_cols, errors='ignore')

X = df_features.select_dtypes(include=[np.number])
X = X.replace([np.inf, -np.inf], np.nan).fillna(0)
X = np.clip(X, -1e9, 1e9)

print(f"ğŸ”¢ æ¸¬è©¦è³‡æ–™ç‰¹å¾µç¶­åº¦: {X.shape}")

# === 4ï¸âƒ£ æª¢æŸ¥æ¬„ä½ä¸€è‡´æ€§ ===
if hasattr(scaler, 'feature_names_in_'):
    scaler_cols = scaler.feature_names_in_
    missing_cols = set(scaler_cols) - set(X.columns)
    if missing_cols:
        print(f"âš ï¸ æ¸¬è©¦è³‡æ–™ç¼ºå°‘æ¬„ä½: {missing_cols}")
        for col in missing_cols:
            X[col] = 0
    X = X[scaler_cols]
    print(f"âœ… å·²å°é½Šç‰¹å¾µæ¬„ä½ï¼Œæœ€çµ‚ç¶­åº¦: {X.shape}")

# === 5ï¸âƒ£ æ¨™æº–åŒ– ===
X_scaled = scaler.transform(X)

# === 6ï¸âƒ£ é©—è­‰ç¶­åº¦ ===
expected_dim = autoencoder.input_shape[1]
current_dim = X_scaled.shape[1]

if current_dim != expected_dim:
    raise ValueError(f"âŒ ç¶­åº¦ä¸åŒ¹é…ï¼æ¨¡å‹éœ€è¦ {expected_dim} ç¶­ï¼Œä½†è³‡æ–™æœ‰ {current_dim} ç¶­")

print(f"âœ… ç‰¹å¾µç¶­åº¦åŒ¹é…: {current_dim}")

# === 7ï¸âƒ£ Autoencoder ç•°å¸¸åµæ¸¬ ===
print("\nğŸ” åŸ·è¡Œ Autoencoder ç•°å¸¸åµæ¸¬...")
recon = autoencoder.predict(X_scaled, verbose=0)
mse = np.mean(np.square(X_scaled - recon), axis=1)

mse_benign = mse[labels == 'BENIGN']
mse_attack = mse[labels != 'BENIGN']

print(f"\nğŸ“Š é‡å»ºèª¤å·®çµ±è¨ˆ:")
print(f"  BENIGN: Mean={mse_benign.mean():.6f}, Median={np.median(mse_benign):.6f}, Max={mse_benign.max():.6f}")
print(f"  Attack: Mean={mse_attack.mean():.6f}, Median={np.median(mse_attack):.6f}, Max={mse_attack.max():.6f}")
print(f"  Ratio (Attack/BENIGN Mean): {mse_attack.mean()/mse_benign.mean():.2f}x")

# === ğŸ†• 8ï¸âƒ£ æ¸¬è©¦å¤šå€‹é–€æª»ç­–ç•¥ ===
print("\n" + "=" * 50)
print("ğŸ¯ æ¸¬è©¦å¤šå€‹é–€æª»ç­–ç•¥")
print("=" * 50)

# å®šç¾©è¦æ¸¬è©¦çš„é–€æª»
test_thresholds = {
    'Recommended': recommended_threshold if recommended_threshold else np.percentile(mse, 95),
    'BENIGN_P90': np.percentile(mse_benign, 90),
    'BENIGN_P95': np.percentile(mse_benign, 95),
    'BENIGN_P97': np.percentile(mse_benign, 97),
    'BENIGN_P99': np.percentile(mse_benign, 99),
    'Mean+2Std': mse_benign.mean() + 2 * mse_benign.std(),
    'Mean+3Std': mse_benign.mean() + 3 * mse_benign.std(),
}

print(f"\n{'ç­–ç•¥':<20} {'é–€æª»å€¼':<12} {'TP':<8} {'FP':<8} {'FN':<8} {'Precision':<10} {'Recall':<10} {'F1':<10}")
print("-" * 95)

threshold_results = []
for name, thresh in sorted(test_thresholds.items(), key=lambda x: x[1]):
    is_ano = (mse > thresh).astype(int)

    tp = ((labels != 'BENIGN') & (is_ano == 1)).sum()
    fp = ((labels == 'BENIGN') & (is_ano == 1)).sum()
    fn = ((labels != 'BENIGN') & (is_ano == 0)).sum()
    tn = ((labels == 'BENIGN') & (is_ano == 0)).sum()

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    print(f"{name:<20} {thresh:<12.6f} {tp:<8} {fp:<8} {fn:<8} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f}")

    threshold_results.append({
        'name': name,
        'threshold': thresh,
        'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn,
        'precision': precision, 'recall': recall, 'f1': f1
    })

# é¸æ“‡æœ€ä½³é–€æª»
best_test_result = max(threshold_results, key=lambda x: x['f1'])
threshold = best_test_result['threshold']
threshold_name = best_test_result['name']

print(f"\nğŸ† æ¸¬è©¦é›†æœ€ä½³é–€æª»: {threshold_name} (Threshold={threshold:.6f}, F1={best_test_result['f1']:.4f})")

# === 9ï¸âƒ£ ä½¿ç”¨æœ€ä½³é–€æª»é€²è¡Œé æ¸¬ ===
is_anomaly = (mse > threshold).astype(int)

print(f"\nğŸ“Š ç•°å¸¸åµæ¸¬çµæœ:")
print(f"  - åµæ¸¬åˆ°ç•°å¸¸: {is_anomaly.sum()} / {len(df)}")
print(f"  - ç•°å¸¸æ¯”ä¾‹: {is_anomaly.sum()/len(df):.2%}")

# === ğŸ”Ÿ MLP åˆ†é¡ç•°å¸¸æ¨£æœ¬ ===
X_anomaly = X_scaled[is_anomaly == 1]

if len(X_anomaly) > 0:
    print(f"\nğŸ§  å° {len(X_anomaly)} å€‹ç•°å¸¸æ¨£æœ¬é€²è¡Œæ”»æ“Šåˆ†é¡...")

    mlp_expected_dim = mlp.input_shape[1]
    if X_anomaly.shape[1] != mlp_expected_dim:
        raise ValueError(f"âŒ MLP ç¶­åº¦ä¸åŒ¹é…ï¼")

    preds = mlp.predict(X_anomaly, verbose=0)
    pred_labels = le.inverse_transform(np.argmax(preds, axis=1))
    print(f"âœ… åˆ†é¡å®Œæˆ")
    print(f"ğŸ“‹ é æ¸¬æ”»æ“Šé¡å‹åˆ†å¸ƒ:\n{pd.Series(pred_labels).value_counts()}")
else:
    pred_labels = []
    print("âš ï¸ æ²’æœ‰åµæ¸¬åˆ°ç•°å¸¸æ¨£æœ¬")

# === 11ï¸âƒ£ çµ„åˆè¼¸å‡ºçµæœ ===
output = pd.DataFrame()
output["Label"] = labels.values
output["anomaly_score"] = mse
output["is_anomaly"] = is_anomaly
output["predicted_attack"] = "BENIGN"

if len(pred_labels) > 0:
    output.loc[is_anomaly == 1, "predicted_attack"] = pred_labels

output.to_csv("prediction_results.csv", index=False)
print("\nğŸ’¾ é æ¸¬çµæœå·²è¼¸å‡º: prediction_results.csv")

# === 12ï¸âƒ£ è©³ç´°è©•ä¼° ===
print("\n" + "=" * 50)
print("ğŸ“Š è©³ç´°è©•ä¼°å ±å‘Š")
print("=" * 50)

tp = best_test_result['tp']
fp = best_test_result['fp']
fn = best_test_result['fn']
tn = best_test_result['tn']

print(f"\nğŸ¯ Autoencoder ç•°å¸¸åµæ¸¬æ€§èƒ½:")
print(f"  True Positives (æ­£ç¢ºåµæ¸¬æ”»æ“Š):  {tp:,}")
print(f"  False Positives (èª¤å ±):         {fp:,}")
print(f"  False Negatives (æ¼å ±):         {fn:,}")
print(f"  True Negatives (æ­£ç¢ºè­˜åˆ¥æ­£å¸¸):  {tn:,}")

accuracy = (tp + tn) / (tp + tn + fp + fn)
precision = best_test_result['precision']
recall = best_test_result['recall']
f1 = best_test_result['f1']

print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ¨™:")
print(f"  Accuracy:  {accuracy:.4f}")
print(f"  Precision: {precision:.4f}")
print(f"  Recall:    {recall:.4f}")
print(f"  F1-Score:  {f1:.4f}")

# === ğŸ†• 13ï¸âƒ£ å„æ”»æ“Šé¡å‹è©³ç´°åˆ†æ ===
print("\n" + "=" * 50)
print("ğŸ¯ å„æ”»æ“Šé¡å‹è©³ç´°åˆ†æ")
print("=" * 50)

print(f"\n{'æ”»æ“Šé¡å‹':<25} {'ç¸½æ•¸':<10} {'åµæ¸¬æ•¸':<10} {'åµæ¸¬ç‡':<10} {'å¹³å‡MSE':<12} {'ä¸­ä½MSE':<12}")
print("-" * 90)

attack_analysis = []
for attack_type in sorted(labels[labels != 'BENIGN'].unique()):
    mask_attack = (labels == attack_type)
    total = mask_attack.sum()
    detected = ((labels == attack_type) & (is_anomaly == 1)).sum()
    rate = detected / total if total > 0 else 0

    mse_type = mse[mask_attack]
    mean_mse = mse_type.mean()
    median_mse = np.median(mse_type)

    print(f"{attack_type:<25} {total:<10} {detected:<10} {rate:<10.2%} {mean_mse:<12.6f} {median_mse:<12.6f}")

    attack_analysis.append({
        'type': attack_type,
        'total': total,
        'detected': detected,
        'rate': rate,
        'mean_mse': mean_mse,
        'median_mse': median_mse
    })

# æ‰¾å‡ºæœ€é›£åµæ¸¬çš„æ”»æ“Š
worst_attack = min(attack_analysis, key=lambda x: x['rate'])
print(f"\nâš ï¸ æœ€é›£åµæ¸¬çš„æ”»æ“Š: {worst_attack['type']} (åµæ¸¬ç‡: {worst_attack['rate']:.2%})")

# === ğŸ†• 14ï¸âƒ£ æ¼å ±æ·±åº¦åˆ†æ ===
print("\n" + "=" * 50)
print("ğŸš« æ¼å ±ï¼ˆFalse Negativesï¼‰æ·±åº¦åˆ†æ")
print("=" * 50)

false_negatives = output[(output['Label'] != 'BENIGN') & (output['is_anomaly'] == 0)]

if len(false_negatives) > 0:
    print(f"\nğŸ“Š æ¼å ±ç¸½æ•¸: {len(false_negatives):,} ({len(false_negatives)/(labels != 'BENIGN').sum():.2%} of all attacks)")
    print(f"ğŸ“Š æ¼å ±çš„ MSE çµ±è¨ˆ:")
    print(f"  - Mean: {false_negatives['anomaly_score'].mean():.6f}")
    print(f"  - Median: {false_negatives['anomaly_score'].median():.6f}")
    print(f"  - Max: {false_negatives['anomaly_score'].max():.6f}")
    print(f"  - Min: {false_negatives['anomaly_score'].min():.6f}")

    print(f"\nğŸ“‹ æ¼å ±æ”»æ“Šé¡å‹åˆ†å¸ƒ:")
    for attack_type in sorted(false_negatives['Label'].unique()):
        fn_type = false_negatives[false_negatives['Label'] == attack_type]
        total_type = (labels == attack_type).sum()
        print(f"  {attack_type:<25}: {len(fn_type):>6} / {total_type:<6} ({len(fn_type)/total_type:>6.2%})")

    # æ¼å ±æ¨£æœ¬èˆ‡æ­£å¸¸æ¨£æœ¬çš„ MSE æ¯”è¼ƒ
    print(f"\nğŸ” æ¼å ±æ¨£æœ¬ vs BENIGN çš„ MSE æ¯”è¼ƒ:")
    fn_mse_mean = false_negatives['anomaly_score'].mean()
    benign_mse_mean = mse_benign.mean()
    print(f"  æ¼å ±å¹³å‡ MSE: {fn_mse_mean:.6f}")
    print(f"  BENIGN å¹³å‡ MSE: {benign_mse_mean:.6f}")
    print(f"  æ¯”å€¼: {fn_mse_mean/benign_mse_mean:.2f}x")

    # å»ºè­°èª¿æ•´
    fn_mse_95 = false_negatives['anomaly_score'].quantile(0.95)
    print(f"\nğŸ’¡ å»ºè­°: è‹¥è¦æŠ“åˆ° 95% çš„æ¼å ±æ”»æ“Šï¼Œé–€æª»éœ€é™è‡³: {fn_mse_95:.6f}")
    print(f"  (ç•¶å‰é–€æª»: {threshold:.6f})")

# === ğŸ†• 15ï¸âƒ£ èª¤å ±åˆ†æ ===
print("\n" + "=" * 50)
print("âš ï¸ èª¤å ±ï¼ˆFalse Positivesï¼‰åˆ†æ")
print("=" * 50)

false_positives = output[(output['Label'] == 'BENIGN') & (output['is_anomaly'] == 1)]

if len(false_positives) > 0:
    print(f"\nğŸ“Š èª¤å ±ç¸½æ•¸: {len(false_positives):,} ({len(false_positives)/(labels == 'BENIGN').sum():.2%} of all BENIGN)")
    print(f"ğŸ“Š èª¤å ±çš„ MSE çµ±è¨ˆ:")
    print(f"  - Mean: {false_positives['anomaly_score'].mean():.6f}")
    print(f"  - Median: {false_positives['anomaly_score'].median():.6f}")
    print(f"  - Max: {false_positives['anomaly_score'].max():.6f}")
    print(f"  - Min: {false_positives['anomaly_score'].min():.6f}")

    print(f"\nğŸ” èª¤å ±æ¨£æœ¬ vs æ”»æ“Šæ¨£æœ¬çš„ MSE æ¯”è¼ƒ:")
    fp_mse_mean = false_positives['anomaly_score'].mean()
    attack_mse_mean = mse_attack.mean()
    print(f"  èª¤å ±å¹³å‡ MSE: {fp_mse_mean:.6f}")
    print(f"  æ”»æ“Šå¹³å‡ MSE: {attack_mse_mean:.6f}")
    print(f"  æ¯”å€¼: {fp_mse_mean/attack_mse_mean:.2f}x")

# === 16ï¸âƒ£ MLP åˆ†é¡æ€§èƒ½è©•ä¼° ===
if len(pred_labels) > 0:
    print("\n" + "=" * 50)
    print("ğŸ§  MLP æ”»æ“Šåˆ†é¡æ€§èƒ½")
    print("=" * 50)

    true_labels_of_anomalies = output.loc[output['is_anomaly'] == 1, 'Label'].values

    correct_classification = (true_labels_of_anomalies == pred_labels).sum()
    classification_acc = correct_classification / len(pred_labels)

    print(f"\nğŸ“Š åˆ†é¡æº–ç¢ºç‡: {classification_acc:.4f} ({correct_classification}/{len(pred_labels)})")

    # åªå°æ”»æ“Šæ¨£æœ¬è©•ä¼°ï¼ˆæ’é™¤ BENIGNï¼‰
    mask_real_attack = true_labels_of_anomalies != 'BENIGN'
    if mask_real_attack.sum() > 0:
        true_attack_labels = true_labels_of_anomalies[mask_real_attack]
        pred_attack_labels = pred_labels[mask_real_attack]

        attack_correct = (true_attack_labels == pred_attack_labels).sum()
        attack_acc = attack_correct / len(true_attack_labels)

        print(f"ğŸ“Š æ”»æ“Šåˆ†é¡æº–ç¢ºç‡ï¼ˆåªçœ‹çœŸå¯¦æ”»æ“Šï¼‰: {attack_acc:.4f} ({attack_correct}/{len(true_attack_labels)})")

        print(f"\nğŸ“‹ æ”»æ“Šåˆ†é¡å ±å‘Šï¼ˆåªçœ‹çœŸå¯¦æ”»æ“Šï¼‰:")
        try:
            report = classification_report(true_attack_labels, pred_attack_labels, zero_division=0)
            print(report)
        except:
            print("  (ç„¡æ³•ç”Ÿæˆå ±å‘Š)")

# === 17ï¸âƒ£ é€²éšè¦–è¦ºåŒ– ===
print("\nğŸ“Š ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")

fig = plt.figure(figsize=(20, 14))

# å­åœ– 1: é‡å»ºèª¤å·®åˆ†ä½ˆ
ax1 = plt.subplot(3, 4, 1)
ax1.hist(mse_benign, bins=100, alpha=0.7, label='BENIGN', color='green', density=True)
ax1.hist(mse_attack, bins=100, alpha=0.7, label='Attack', color='red', density=True)
ax1.axvline(threshold, color='black', linestyle='--', linewidth=2,
            label=f'Threshold={threshold:.4f}\n({threshold_name})')
ax1.set_xlabel('Reconstruction Error (MSE)')
ax1.set_ylabel('Density')
ax1.set_title('Reconstruction Error Distribution', fontsize=11, fontweight='bold')
ax1.legend(fontsize=8)
ax1.grid(True, alpha=0.3)

# å­åœ– 2: æ··æ·†çŸ©é™£
ax2 = plt.subplot(3, 4, 2)
cm = np.array([[tn, fp], [fn, tp]])
sns.heatmap(cm, annot=True, fmt=',d', cmap='Blues', ax=ax2,
            xticklabels=['Pred\nNormal', 'Pred\nAttack'],
            yticklabels=['True\nNormal', 'True\nAttack'],
            cbar_kws={'label': 'Count'})
ax2.set_title('Confusion Matrix', fontsize=11, fontweight='bold')

# å­åœ– 3: é–€æª»ç­–ç•¥æ¯”è¼ƒï¼ˆF1-Scoreï¼‰
ax3 = plt.subplot(3, 4, 3)
strategy_names = [r['name'] for r in threshold_results]
f1_scores = [r['f1'] for r in threshold_results]
colors = ['gold' if r['name'] == threshold_name else 'steelblue' for r in threshold_results]

bars = ax3.barh(strategy_names, f1_scores, color=colors)
ax3.set_xlabel('F1-Score')
ax3.set_title('Threshold Strategy F1-Score', fontsize=11, fontweight='bold')
ax3.set_xlim(0, 1)
ax3.grid(True, alpha=0.3, axis='x')

for i, (bar, score) in enumerate(zip(bars, f1_scores)):
    ax3.text(score + 0.02, i, f'{score:.3f}', va='center', fontsize=8)

# å­åœ– 4: æ€§èƒ½æŒ‡æ¨™é›·é”åœ–
ax4 = plt.subplot(3, 4, 4, projection='polar')
metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy']
values = [precision, recall, f1, accuracy]

angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
values += values[:1]
angles += angles[:1]

ax4.plot(angles, values, 'o-', linewidth=2, color='blue')
ax4.fill(angles, values, alpha=0.25, color='blue')
ax4.set_xticks(angles[:-1])
ax4.set_xticklabels(metrics, fontsize=9)
ax4.set_ylim(0, 1)
ax4.set_title('Performance Metrics', fontsize=11, fontweight='bold', pad=15)
ax4.grid(True)

# å­åœ– 5: å„æ”»æ“Šé¡å‹åµæ¸¬ç‡
ax5 = plt.subplot(3, 4, 5)
attack_types = [a['type'] for a in attack_analysis]
detection_rates = [a['rate'] * 100 for a in attack_analysis]
colors_bar = ['green' if r >= 70 else 'orange' if r >= 50 else 'red' for r in detection_rates]

bars = ax5.barh(attack_types, detection_rates, color=colors_bar)
ax5.set_xlabel('Detection Rate (%)')
ax5.set_title('Detection Rate by Attack Type', fontsize=11, fontweight='bold')
ax5.set_xlim(0, 100)
ax5.grid(True, alpha=0.3, axis='x')

for i, (bar, rate) in enumerate(zip(bars, detection_rates)):
    ax5.text(rate + 2, i, f'{rate:.1f}%', va='center', fontsize=8, fontweight='bold')

# å­åœ– 6: å„æ”»æ“Šé¡å‹ MSE åˆ†ä½ˆ
ax6 = plt.subplot(3, 4, 6)
attack_types_plot = [a['type'] for a in attack_analysis]
mean_mses = [a['mean_mse'] for a in attack_analysis]
median_mses = [a['median_mse'] for a in attack_analysis]

x = np.arange(len(attack_types_plot))
width = 0.35

bars1 = ax6.barh(x - width/2, mean_mses, width, label='Mean MSE', color='steelblue', alpha=0.8)
bars2 = ax6.barh(x + width/2, median_mses, width, label='Median MSE', color='coral', alpha=0.8)

ax6.set_xlabel('MSE')
ax6.set_title('Mean vs Median MSE by Attack Type', fontsize=11, fontweight='bold')
ax6.set_yticks(x)
ax6.set_yticklabels(attack_types_plot, fontsize=8)
ax6.legend(fontsize=8)
ax6.grid(True, alpha=0.3, axis='x')

# å­åœ– 7: MSE æ•£é»åœ–ï¼ˆæ¡æ¨£ï¼‰
ax7 = plt.subplot(3, 4, 7)
sample_size = min(5000, len(mse))
sample_indices = np.random.choice(len(mse), sample_size, replace=False)
colors_scatter = ['green' if l == 'BENIGN' else 'red' for l in labels.iloc[sample_indices]]

ax7.scatter(sample_indices, mse[sample_indices], c=colors_scatter, alpha=0.4, s=2)
ax7.axhline(threshold, color='black', linestyle='--', linewidth=2, label='Threshold')
ax7.set_xlabel('Sample Index')
ax7.set_ylabel('MSE')
ax7.set_title('MSE Scatter (Green=BENIGN, Red=Attack)', fontsize=11, fontweight='bold')
ax7.legend(fontsize=8)
ax7.grid(True, alpha=0.3)

# å­åœ– 8: æ¼å ± MSE åˆ†ä½ˆ
ax8 = plt.subplot(3, 4, 8)
if len(false_negatives) > 0:
    ax8.hist(false_negatives['anomaly_score'], bins=50, alpha=0.7, color='orange', label='False Negatives')
    ax8.hist(mse_benign, bins=50, alpha=0.5, color='green', label='BENIGN')
    ax8.axvline(threshold, color='black', linestyle='--', linewidth=2, label='Threshold')
    ax8.set_xlabel('MSE')
    ax8.set_ylabel('Count')
    ax8.set_title('False Negatives MSE Distribution', fontsize=11, fontweight='bold')
    ax8.legend(fontsize=8)
    ax8.grid(True, alpha=0.3)
else:
    ax8.text(0.5, 0.5, 'No False Negatives', ha='center', va='center', fontsize=12)
    ax8.set_title('False Negatives MSE Distribution', fontsize=11, fontweight='bold')

# å­åœ– 9: èª¤å ± MSE åˆ†ä½ˆ
ax9 = plt.subplot(3, 4, 9)
if len(false_positives) > 0:
    ax9.hist(false_positives['anomaly_score'], bins=50, alpha=0.7, color='red', label='False Positives')
    ax9.hist(mse_attack, bins=50, alpha=0.5, color='orange', label='Attack')
    ax9.axvline(threshold, color='black', linestyle='--', linewidth=2, label='Threshold')
    ax9.set_xlabel('MSE')
    ax9.set_ylabel('Count')
    ax9.set_title('False Positives MSE Distribution', fontsize=11, fontweight='bold')
    ax9.legend(fontsize=8)
    ax9.grid(True, alpha=0.3)
else:
    ax9.text(0.5, 0.5, 'No False Positives', ha='center', va='center', fontsize=12)
    ax9.set_title('False Positives MSE Distribution', fontsize=11, fontweight='bold')

# å­åœ– 10: Precision vs Recall æ¬Šè¡¡
ax10 = plt.subplot(3, 4, 10)
precisions = [r['precision'] for r in threshold_results]
recalls = [r['recall'] for r in threshold_results]
strategy_labels = [r['name'] for r in threshold_results]

ax10.plot(recalls, precisions, 'b-o', linewidth=2, markersize=6)
# æ¨™è¨˜ç•¶å‰ç­–ç•¥
current_idx = strategy_labels.index(threshold_name)
ax10.plot(recalls[current_idx], precisions[current_idx], 'r*', markersize=15, label='Current')
ax10.set_xlabel('Recall (Detection Rate)')
ax10.set_ylabel('Precision')
ax10.set_title('Precision-Recall Curve', fontsize=11, fontweight='bold')
ax10.legend(fontsize=8)
ax10.grid(True, alpha=0.3)
ax10.set_xlim(-0.05, 1.05)
ax10.set_ylim(-0.05, 1.05)

# å­åœ– 11: é æ¸¬çµæœåˆ†å¸ƒ
ax11 = plt.subplot(3, 4, 11)
pred_counts = output["predicted_attack"].value_counts()
pred_counts.plot(kind='bar', ax=ax11, color='steelblue')
ax11.set_title('Predicted Attack Types', fontsize=11, fontweight='bold')
ax11.set_xlabel('Attack Type')
ax11.set_ylabel('Count')
ax11.tick_params(axis='x', rotation=45, labelsize=8)
ax11.grid(True, alpha=0.3, axis='y')

# å­åœ– 12: MLP æ··æ·†çŸ©é™£ï¼ˆå¦‚æœæœ‰ï¼‰
ax12 = plt.subplot(3, 4, 12)
if len(pred_labels) > 0:
    mask_real_attack = true_labels_of_anomalies != 'BENIGN'
    if mask_real_attack.sum() > 10:  # è‡³å°‘è¦æœ‰ 10 å€‹æ¨£æœ¬
        true_attack_labels = true_labels_of_anomalies[mask_real_attack]
        pred_attack_labels = pred_labels[mask_real_attack]

        unique_labels = sorted(set(true_attack_labels) | set(pred_attack_labels))
        cm_mlp = confusion_matrix(true_attack_labels, pred_attack_labels, labels=unique_labels)

        sns.heatmap(cm_mlp, annot=True, fmt='d', cmap='Greens', ax=ax12,
                   xticklabels=[l[:10] for l in unique_labels],
                   yticklabels=[l[:10] for l in unique_labels],
                   cbar_kws={'label': 'Count'})
        ax12.set_title('MLP Classification Matrix', fontsize=11, fontweight='bold')
        ax12.set_xlabel('Predicted')
        ax12.set_ylabel('True')
    else:
        ax12.text(0.5, 0.5, 'Insufficient Attack Samples', ha='center', va='center', fontsize=10)
        ax12.set_title('MLP Classification Matrix', fontsize=11, fontweight='bold')
else:
    ax12.text(0.5, 0.5, 'No MLP Classification', ha='center', va='center', fontsize=10)
    ax12.set_title('MLP Classification Matrix', fontsize=11, fontweight='bold')

plt.tight_layout()
plt.savefig('test_final_analysis.png', dpi=150, bbox_inches='tight')
print("âœ… å·²ä¿å­˜æœ€çµ‚æ¸¬è©¦åˆ†æåœ–: test_final_analysis.png")

plt.show()

print("\n" + "=" * 50)
print("âœ… æ¸¬è©¦å®Œæˆï¼ˆæœ€çµ‚æ”¹è‰¯ç‰ˆï¼‰ï¼")
print("=" * 50)
print(f"ğŸ“Š æœ€çµ‚çµæœç¸½çµ:")
print(f"  - æ¸¬è©¦æ¨£æœ¬æ•¸: {len(df):,}")
print(f"  - ä½¿ç”¨é–€æª»: {threshold:.6f} ({threshold_name})")
print(f"  - åµæ¸¬åˆ°ç•°å¸¸: {is_anomaly.sum():,}")
print(f"  - Precision: {precision:.4f}")
print(f"  - Recall: {recall:.4f}")
print(f"  - F1-Score: {f1:.4f}")
print(f"  - Accuracy: {accuracy:.4f}")
if len(pred_labels) > 0:
    print(f"  - MLP åˆ†é¡æº–ç¢ºç‡: {classification_acc:.4f}")
print("=" * 50)